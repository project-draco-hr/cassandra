def do_copy(self, parsed):
    '\n        COPY [cqlsh only]\n\n          COPY x FROM: Imports CSV data into a Cassandra table\n          COPY x TO: Exports data from a Cassandra table in CSV format.\n\n        COPY <table_name> [ ( column [, ...] ) ]\n             FROM ( \'<filename>\' | STDIN )\n             [ WITH <option>=\'value\' [AND ...] ];\n\n        COPY <table_name> [ ( column [, ...] ) ]\n             TO ( \'<filename>\' | STDOUT )\n             [ WITH <option>=\'value\' [AND ...] ];\n\n        Available options and defaults:\n\n          DELIMITER=\',\'           - character that appears between records\n          QUOTE=\'"\'               - quoting character to be used to quote fields\n          ESCAPE=\'\\\'              - character to appear before the QUOTE char when quoted\n          HEADER=false            - whether to ignore the first line\n          NULL=\'\'                 - string that represents a null value\n          ENCODING=\'utf8\'         - encoding for CSV output (COPY TO)\n          TIMEFORMAT=             - timestamp strftime format (COPY TO)\n            \'%Y-%m-%d %H:%M:%S%z\'   defaults to time_format value in cqlshrc\n          MAXREQUESTS=6           - the maximum number of requests each worker process can work on in parallel (COPY TO)\n          PAGESIZE=1000           - the page size for fetching results (COPY TO)\n          PAGETIMEOUT=10          - the page timeout for fetching results (COPY TO)\n          MAXATTEMPTS=5           - the maximum number of attempts for errors\n          CHUNKSIZE=1000          - the size of chunks passed to worker processes (COPY FROM)\n          INGESTRATE=100000       - an approximate ingest rate in rows per second (COPY FROM)\n          MAXBATCHSIZE=20         - the maximum size of an import batch (COPY FROM)\n          MINBATCHSIZE=2          - the minimum size of an import batch (COPY FROM)\n          REPORTFREQUENCY=0.25    - the frequency with which we display status updates in seconds\n          TTL=3600                - the time to live in seconds, by default data will not expire (COPY FROM)\n\n        When entering CSV data on STDIN, you can use the sequence "\\."\n        on a line by itself to end the data input.\n        '
    ks = self.cql_unprotect_name(parsed.get_binding('ksname', None))
    if (ks is None):
        ks = self.current_keyspace
        if (ks is None):
            raise NoKeyspaceError('Not in any keyspace.')
    cf = self.cql_unprotect_name(parsed.get_binding('cfname'))
    columns = parsed.get_binding('colnames', None)
    if (columns is not None):
        columns = map(self.cql_unprotect_name, columns)
    else:
        columns = self.get_column_names(ks, cf)
    fname = parsed.get_binding('fname', None)
    if (fname is not None):
        fname = os.path.expanduser(self.cql_unprotect_value(fname))
    copyoptnames = map(str.lower, parsed.get_binding('optnames', ()))
    copyoptvals = map(self.cql_unprotect_value, parsed.get_binding('optvals', ()))
    cleancopyoptvals = [optval.decode('string-escape') for optval in copyoptvals]
    opts = dict(zip(copyoptnames, cleancopyoptvals))
    print ('\nStarting copy of %s.%s with columns %s.' % (ks, cf, columns))
    timestart = time.time()
    direction = parsed.get_binding('dir').upper()
    if (direction == 'FROM'):
        rows = self.perform_csv_import(ks, cf, columns, fname, opts)
        verb = 'imported'
    elif (direction == 'TO'):
        rows = self.perform_csv_export(ks, cf, columns, fname, opts)
        verb = 'exported'
    else:
        raise SyntaxError(('Unknown direction %s' % direction))
    timeend = time.time()
    print ('\n%d rows %s in %s.' % (rows, verb, describe_interval((timeend - timestart))))
