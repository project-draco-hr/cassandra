{
  if (insertStatement == null) {
synchronized (this) {
      if (insertStatement == null) {
        maybeLoadSchemaInfo(settings);
        Set<ColumnMetadata> keyColumns=com.google.common.collect.Sets.newHashSet(tableMetaData.getPrimaryKey());
        Set<ColumnMetadata> allColumns=com.google.common.collect.Sets.newHashSet(tableMetaData.getColumns());
        boolean isKeyOnlyTable=(keyColumns.size() == allColumns.size());
        if (!isKeyOnlyTable && (keyColumns.size() == (allColumns.size() - 1))) {
          com.google.common.collect.Sets.SetView diff=com.google.common.collect.Sets.difference(allColumns,keyColumns);
          for (          Object obj : diff) {
            ColumnMetadata col=(ColumnMetadata)obj;
            isKeyOnlyTable=col.getName().isEmpty();
            break;
          }
        }
        StringBuilder sb=new StringBuilder();
        if (!isKeyOnlyTable) {
          sb.append("UPDATE \"").append(tableName).append("\" SET ");
          StringBuilder pred=new StringBuilder();
          pred.append(" WHERE ");
          boolean firstCol=true;
          boolean firstPred=true;
          for (          ColumnMetadata c : tableMetaData.getColumns()) {
            if (keyColumns.contains(c)) {
              if (firstPred)               firstPred=false;
 else               pred.append(" AND ");
              pred.append(c.getName()).append(" = ?");
            }
 else {
              if (firstCol)               firstCol=false;
 else               sb.append(',');
              sb.append(c.getName()).append(" = ");
switch (c.getType().getName()) {
case SET:
case LIST:
case COUNTER:
                sb.append(c.getName()).append(" + ?");
              break;
default :
            sb.append("?");
          break;
      }
    }
  }
  sb.append(pred);
}
 else {
  sb.append("INSERT INTO \"").append(tableName).append("\" (");
  StringBuilder value=new StringBuilder();
  for (  ColumnMetadata c : tableMetaData.getPrimaryKey()) {
    sb.append(c.getName()).append(", ");
    value.append("?, ");
  }
  sb.delete(sb.lastIndexOf(","),sb.length());
  value.delete(value.lastIndexOf(","),value.length());
  sb.append(") ").append("values(").append(value).append(')');
}
if (insert == null) insert=new HashMap<>();
lowerCase(insert);
partitions=select(settings.insert.batchsize,"partitions","fixed(1)",insert,OptionDistribution.BUILDER);
selectchance=select(settings.insert.selectRatio,"select","fixed(1)/1",insert,OptionRatioDistribution.BUILDER);
rowPopulation=select(settings.insert.rowPopulationRatio,"row-population","fixed(1)/1",insert,OptionRatioDistribution.BUILDER);
batchType=settings.insert.batchType != null ? settings.insert.batchType : !insert.containsKey("batchtype") ? BatchStatement.Type.LOGGED : BatchStatement.Type.valueOf(insert.remove("batchtype"));
if (!insert.isEmpty()) throw new IllegalArgumentException("Unrecognised insert option(s): " + insert);
Distribution visits=settings.insert.visits.get();
double minBatchSize=selectchance.get().min() * partitions.get().minValue() * generator.minRowCount* (1d / visits.maxValue());
double maxBatchSize=selectchance.get().max() * partitions.get().maxValue() * generator.maxRowCount* (1d / visits.minValue());
System.out.printf("Generating batches with [%d..%d] partitions and [%.0f..%.0f] rows (of [%.0f..%.0f] total rows in the partitions)%n",partitions.get().minValue(),partitions.get().maxValue(),minBatchSize,maxBatchSize,partitions.get().minValue() * generator.minRowCount,partitions.get().maxValue() * generator.maxRowCount);
if (generator.maxRowCount > 100 * 1000 * 1000) System.err.printf("WARNING: You have defined a schema that permits very large partitions (%.0f max rows (>100M))%n",generator.maxRowCount);
if (batchType == BatchStatement.Type.LOGGED && maxBatchSize > 65535) {
  System.err.printf("ERROR: You have defined a workload that generates batches with more than 65k rows (%.0f), but have required the use of LOGGED batches. There is a 65k row limit on a single batch.%n",selectchance.get().max() * partitions.get().maxValue() * generator.maxRowCount);
  System.exit(1);
}
if (maxBatchSize > 100000) System.err.printf("WARNING: You have defined a schema that permits very large batches (%.0f max rows (>100K)). This may OOM this stress client, or the server.%n",selectchance.get().max() * partitions.get().maxValue() * generator.maxRowCount);
JavaDriverClient client=settings.getJavaDriverClient();
String query=sb.toString();
if (settings.mode.api != ConnectionAPI.JAVA_DRIVER_NATIVE) {
  try {
    thriftInsertId=settings.getThriftClient().prepare_cql3_query(query,Compression.NONE);
  }
 catch (  TException e) {
    throw new RuntimeException(e);
  }
}
insertStatement=client.prepare(query);
}
}
}
return new SchemaInsert(timer,settings,generator,seedManager,partitions.get(),selectchance.get(),rowPopulation.get(),thriftInsertId,insertStatement,ThriftConversion.fromThrift(settings.command.consistencyLevel),batchType);
}
