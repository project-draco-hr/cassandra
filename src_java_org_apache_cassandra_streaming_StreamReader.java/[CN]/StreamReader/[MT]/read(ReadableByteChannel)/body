{
  long totalSize=totalSize();
  Pair<String,String> kscf=Schema.instance.getCF(cfId);
  ColumnFamilyStore cfs=null;
  if (kscf != null)   cfs=Keyspace.open(kscf.left).getColumnFamilyStore(kscf.right);
  if (kscf == null || cfs == null) {
    throw new IOException("CF " + cfId + " was dropped during streaming");
  }
  logger.debug("[Stream #{}] Start receiving file #{} from {}, repairedAt = {}, size = {}, ks = '{}', table = '{}'.",session.planId(),fileSeqNum,session.peer,repairedAt,totalSize,cfs.keyspace.getName(),cfs.getColumnFamilyName());
  TrackedInputStream in=new TrackedInputStream(new LZFInputStream(Channels.newInputStream(channel)));
  StreamDeserializer deserializer=new StreamDeserializer(cfs.metadata,in,inputVersion,getHeader(cfs.metadata),totalSize,session.planId());
  SSTableMultiWriter writer=null;
  try {
    writer=createWriter(cfs,totalSize,repairedAt,format);
    while (in.getBytesRead() < totalSize) {
      writePartition(deserializer,writer);
      session.progress(writer.getFilename(),ProgressInfo.Direction.IN,in.getBytesRead(),totalSize);
    }
    logger.debug("[Stream #{}] Finished receiving file #{} from {} readBytes = {}, totalSize = {}",session.planId(),fileSeqNum,session.peer,FBUtilities.prettyPrintMemory(in.getBytesRead()),FBUtilities.prettyPrintMemory(totalSize));
    return writer;
  }
 catch (  Throwable e) {
    if (deserializer != null)     logger.warn("[Stream {}] Error while reading partition {} from stream on ks='{}' and table='{}'.",session.planId(),deserializer.partitionKey(),cfs.keyspace.getName(),cfs.getTableName());
    if (writer != null) {
      writer.abort(e);
    }
    throw Throwables.propagate(e);
  }
 finally {
    if (deserializer != null)     deserializer.cleanup();
  }
}
