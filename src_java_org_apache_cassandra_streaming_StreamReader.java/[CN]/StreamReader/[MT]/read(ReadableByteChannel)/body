{
  long totalSize=totalSize();
  Pair<String,String> kscf=Schema.instance.getCF(cfId);
  ColumnFamilyStore cfs=null;
  if (kscf != null)   cfs=Keyspace.open(kscf.left).getColumnFamilyStore(kscf.right);
  if (kscf == null || cfs == null) {
    throw new IOException("CF " + cfId + " was dropped during streaming");
  }
  logger.debug("[Stream #{}] Start receiving file #{} from {}, repairedAt = {}, size = {}, ks = '{}', table = '{}'.",session.planId(),fileSeqNum,session.peer,repairedAt,totalSize,cfs.keyspace.getName(),cfs.getColumnFamilyName());
  DataInputStream dis=new DataInputStream(new LZFInputStream(Channels.newInputStream(channel)));
  BytesReadTracker in=new BytesReadTracker(dis);
  StreamDeserializer deserializer=new StreamDeserializer(cfs.metadata,in,inputVersion,header.toHeader(cfs.metadata));
  SSTableMultiWriter writer=null;
  try {
    writer=createWriter(cfs,totalSize,repairedAt,format);
    while (in.getBytesRead() < totalSize) {
      writePartition(deserializer,writer);
      session.progress(writer.getFilename(),ProgressInfo.Direction.IN,in.getBytesRead(),totalSize);
    }
    logger.debug("[Stream #{}] Finished receiving file #{} from {} readBytes = {}, totalSize = {}",session.planId(),fileSeqNum,session.peer,in.getBytesRead(),totalSize);
    return writer;
  }
 catch (  Throwable e) {
    if (deserializer != null)     logger.warn("[Stream {}] Error while reading partition {} from stream on ks='{}' and table='{}'.",session.planId(),deserializer.partitionKey(),cfs.keyspace.getName(),cfs.getColumnFamilyName());
    if (writer != null) {
      writer.abort(e);
    }
    drain(dis,in.getBytesRead());
    if (e instanceof IOException)     throw (IOException)e;
 else     throw Throwables.propagate(e);
  }
}
