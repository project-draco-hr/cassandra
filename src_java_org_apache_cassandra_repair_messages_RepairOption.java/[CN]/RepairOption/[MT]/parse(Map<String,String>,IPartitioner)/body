{
  RepairParallelism parallelism=RepairParallelism.fromName(options.get(PARALLELISM_KEY));
  boolean primaryRange=Boolean.parseBoolean(options.get(PRIMARY_RANGE_KEY));
  boolean incremental=Boolean.parseBoolean(options.get(INCREMENTAL_KEY));
  boolean trace=Boolean.parseBoolean(options.get(TRACE_KEY));
  boolean pullRepair=Boolean.parseBoolean(options.get(PULL_REPAIR_KEY));
  int jobThreads=1;
  if (options.containsKey(JOB_THREADS_KEY)) {
    try {
      jobThreads=Integer.parseInt(options.get(JOB_THREADS_KEY));
    }
 catch (    NumberFormatException ignore) {
    }
  }
  String rangesStr=options.get(RANGES_KEY);
  Set<Range<Token>> ranges=new HashSet<>();
  if (rangesStr != null) {
    if (incremental)     logger.warn("Incremental repair can't be requested with subrange repair " + "because each subrange repair would generate an anti-compacted table. " + "The repair will occur but without anti-compaction.");
    StringTokenizer tokenizer=new StringTokenizer(rangesStr,",");
    while (tokenizer.hasMoreTokens()) {
      String[] rangeStr=tokenizer.nextToken().split(":",2);
      if (rangeStr.length < 2) {
        continue;
      }
      Token parsedBeginToken=partitioner.getTokenFactory().fromString(rangeStr[0].trim());
      Token parsedEndToken=partitioner.getTokenFactory().fromString(rangeStr[1].trim());
      ranges.add(new Range<>(parsedBeginToken,parsedEndToken));
    }
  }
  RepairOption option=new RepairOption(parallelism,primaryRange,incremental,trace,jobThreads,ranges,!ranges.isEmpty(),pullRepair);
  String dataCentersStr=options.get(DATACENTERS_KEY);
  Collection<String> dataCenters=new HashSet<>();
  if (dataCentersStr != null) {
    StringTokenizer tokenizer=new StringTokenizer(dataCentersStr,",");
    while (tokenizer.hasMoreTokens()) {
      dataCenters.add(tokenizer.nextToken().trim());
    }
    option.getDataCenters().addAll(dataCenters);
  }
  String hostsStr=options.get(HOSTS_KEY);
  Collection<String> hosts=new HashSet<>();
  if (hostsStr != null) {
    StringTokenizer tokenizer=new StringTokenizer(hostsStr,",");
    while (tokenizer.hasMoreTokens()) {
      hosts.add(tokenizer.nextToken().trim());
    }
    option.getHosts().addAll(hosts);
  }
  String cfStr=options.get(COLUMNFAMILIES_KEY);
  if (cfStr != null) {
    Collection<String> columnFamilies=new HashSet<>();
    StringTokenizer tokenizer=new StringTokenizer(cfStr,",");
    while (tokenizer.hasMoreTokens()) {
      columnFamilies.add(tokenizer.nextToken().trim());
    }
    option.getColumnFamilies().addAll(columnFamilies);
  }
  if (jobThreads > MAX_JOB_THREADS) {
    throw new IllegalArgumentException("Too many job threads. Max is " + MAX_JOB_THREADS);
  }
  if (!dataCenters.isEmpty() && !hosts.isEmpty()) {
    throw new IllegalArgumentException("Cannot combine -dc and -hosts options.");
  }
  if (primaryRange && (!dataCenters.isEmpty() || !hosts.isEmpty())) {
    throw new IllegalArgumentException("You need to run primary range repair on all nodes in the cluster.");
  }
  if (pullRepair) {
    if (hosts.size() != 2) {
      throw new IllegalArgumentException("Pull repair can only be performed between two hosts. Please specify two hosts, one of which must be this host.");
    }
 else     if (ranges.isEmpty()) {
      throw new IllegalArgumentException("Token ranges must be specified when performing pull repair. Please specify at least one token range which both hosts have in common.");
    }
  }
  return option;
}
