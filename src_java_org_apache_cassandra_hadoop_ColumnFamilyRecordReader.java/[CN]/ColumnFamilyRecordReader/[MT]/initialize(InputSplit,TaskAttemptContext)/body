{
  this.split=(ColumnFamilySplit)split;
  Configuration conf=HadoopCompat.getConfiguration(context);
  KeyRange jobRange=ConfigHelper.getInputKeyRange(conf);
  filter=jobRange == null ? null : jobRange.row_filter;
  predicate=ConfigHelper.getInputSlicePredicate(conf);
  boolean widerows=ConfigHelper.getInputIsWide(conf);
  isEmptyPredicate=isEmptyPredicate(predicate);
  totalRowCount=(this.split.getLength() < Long.MAX_VALUE) ? (int)this.split.getLength() : ConfigHelper.getInputSplitSize(conf);
  batchSize=ConfigHelper.getRangeBatchSize(conf);
  cfName=ConfigHelper.getInputColumnFamily(conf);
  consistencyLevel=ConsistencyLevel.valueOf(ConfigHelper.getReadConsistencyLevel(conf));
  keyspace=ConfigHelper.getInputKeyspace(conf);
  if (batchSize < 2)   throw new IllegalArgumentException("Minimum batchSize is 2.  Suggested batchSize is 100 or more");
  String[] locations=getLocations();
  int port=ConfigHelper.getInputRpcPort(conf);
  Exception lastException=null;
  for (  String location : locations) {
    try {
      client=ColumnFamilyInputFormat.createAuthenticatedClient(location,port,conf);
      break;
    }
 catch (    Exception e) {
      lastException=e;
      logger.warn("Failed to create authenticated client to {}:{}",location,port);
    }
  }
  if (client == null && lastException != null)   throw new RuntimeException(lastException);
  iter=widerows ? new WideRowIterator() : new StaticRowIterator();
  logger.trace("created {}",iter);
}
